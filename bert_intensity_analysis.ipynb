{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# **BERT-Based Intensity Analysis**\n", "This notebook processes text data to classify emotions into *Happiness, Anger, and Sadness* using BERT."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install required libraries\n", "!pip install transformers torch pandas scikit-learn\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 1: Import Dependencies**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import torch\n", "from transformers import BertTokenizer, BertForSequenceClassification\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import LabelEncoder\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 2: Load and Merge Datasets**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load datasets (Ensure CSV files are in the same directory)\n", "happiness_df = pd.read_csv('happiness.csv')\n", "sadness_df = pd.read_csv('sadness.csv')\n", "anger_df = pd.read_csv('anger.csv')\n", "\n", "# Assign labels\n", "happiness_df['Label'] = 'Happiness'\n", "sadness_df['Label'] = 'Sadness'\n", "anger_df['Label'] = 'Anger'\n", "\n", "# Merge datasets\n", "df = pd.concat([happiness_df, sadness_df, anger_df], ignore_index=True)\n", "df.to_csv('emotion_dataset.csv', index=False)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 3: Encode Labels & Split Data**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Encode labels\n", "label_encoder = LabelEncoder()\n", "df['encoded_label'] = label_encoder.fit_transform(df['Label'])\n", "\n", "# Split dataset\n", "train_texts, test_texts, train_labels, test_labels = train_test_split(\n", "    df['Text'].tolist(), df['encoded_label'].tolist(), test_size=0.2, random_state=42\n", ")\n", "print(f'Training samples: {len(train_texts)}, Testing samples: {len(test_texts)}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 4: Tokenize Data using BERT**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load BERT tokenizer\n", "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n", "\n", "# Tokenize datasets\n", "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n", "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n", "\n", "print('Tokenization complete!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 5: Train BERT Model**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load BERT model\n", "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n", "\n", "# Move model to GPU if available\n", "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "model.to(device)\n", "\n", "# Define optimizer\n", "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n", "\n", "print('BERT model loaded and ready for training!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 6: Save the Trained Model**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save model and tokenizer\n", "model.save_pretrained('bert_intensity_model')\n", "tokenizer.save_pretrained('bert_intensity_model')\n", "print('Model saved successfully!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 7: Predict on New Text**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Function for prediction\n", "def predict_emotion(text):\n", "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n", "    inputs = {key: val.to(device) for key, val in inputs.items()}\n", "    \n", "    with torch.no_grad():\n", "        outputs = model(**inputs)\n", "        prediction = torch.argmax(outputs.logits, dim=1).item()\n", "    \n", "    labels = {0: 'Happiness', 1: 'Anger', 2: 'Sadness'}\n", "    return labels[prediction]\n", "\n", "# Test the function\n", "print(predict_emotion('I am feeling so happy today!'))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 4}